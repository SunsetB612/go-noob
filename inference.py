import os
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
from extract_features import extract_features  # ç‰¹å¾æå–å‡½æ•°
from utils import postprocess_prediction       # åå¤„ç†å‡½æ•°


# æ¨¡å‹ç»“æ„åº”ä¸ train.py ä¸­å®Œå…¨ä¸€è‡´
class CNNVAD(nn.Module):
    def __init__(self):
        super(CNNVAD, self).__init__()
        self.net = nn.Sequential(
            nn.Conv1d(40, 64, kernel_size=1),
            nn.ReLU(),
            nn.Conv1d(64, 64, kernel_size=1),
            nn.ReLU(),
            nn.Conv1d(64, 1, kernel_size=1),
            nn.Sigmoid()
        )

    def forward(self, x):  # x: [B, 40, T]
        return self.net(x).squeeze(1)  # â†’ [B, T]


def infer(wav_dir="data/wav", model_path="model/cnn_vad_model.pth", output_dir="output"):
    # åŠ è½½æ¨¡å‹
    model = CNNVAD()
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.eval()

    # è¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_dir, exist_ok=True)

    wav_dir = Path(wav_dir)
    for wav_file in wav_dir.glob("*.wav"):
        print(f"\nğŸ” Processing {wav_file.name}...")

        # 1. æå– MFCC ç‰¹å¾ï¼ˆshape: [T, 40]ï¼‰
        mfcc = extract_features(str(wav_file))  # æ¯å¸§40ç»´

        # 2. è½¬ä¸ºè¾“å…¥æ ¼å¼ [1, 40, T]
        X = torch.tensor(mfcc.T, dtype=torch.float32).unsqueeze(0)  # [T, 40] -> [1, 40, T]

        # 3. æ¨ç† [1, T]
        with torch.no_grad():
            pred = model(X).squeeze().numpy()  # [T]

        # 4. åå¤„ç†
        intervals = postprocess_prediction(pred, threshold=0.5, min_len=3)

        # 5. æ‰“å°å¹¶ä¿å­˜ç»“æœ
        print(f"âœ… Detected {len(intervals)} speech segments:")
        for i, (start, end) in enumerate(intervals):
            print(f"   Segment {i+1}: Frames {start} to {end}")

        # è¾“å‡ºåˆ°æ–‡ä»¶
        out_path = Path(output_dir) / f"{wav_file.stem}_vad.txt"
        with open(out_path, "w") as f:
            for start, end in intervals:
                f.write(f"{start} {end}\n")


if __name__ == '__main__':
    infer()
